{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install onnx onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import onnx\n",
    "import onnxruntime\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = '''person\n",
    "bicycle\n",
    "car\n",
    "motorbike\n",
    "aeroplane\n",
    "bus\n",
    "train\n",
    "truck\n",
    "boat\n",
    "traffic light\n",
    "fire hydrant\n",
    "stop sign\n",
    "parking meter\n",
    "bench\n",
    "bird\n",
    "cat\n",
    "dog\n",
    "horse\n",
    "sheep\n",
    "cow\n",
    "elephant\n",
    "bear\n",
    "zebra\n",
    "giraffe\n",
    "backpack\n",
    "umbrella\n",
    "handbag\n",
    "tie\n",
    "suitcase\n",
    "frisbee\n",
    "skis\n",
    "snowboard\n",
    "sports ball\n",
    "kite\n",
    "baseball bat\n",
    "baseball glove\n",
    "skateboard\n",
    "surfboard\n",
    "tennis racket\n",
    "bottle\n",
    "wine glass\n",
    "cup\n",
    "fork\n",
    "knife\n",
    "spoon\n",
    "bowl\n",
    "banana\n",
    "apple\n",
    "sandwich\n",
    "orange\n",
    "broccoli\n",
    "carrot\n",
    "hot dog\n",
    "pizza\n",
    "donut\n",
    "cake\n",
    "chair\n",
    "sofa\n",
    "pottedplant\n",
    "bed\n",
    "diningtable\n",
    "toilet\n",
    "tvmonitor\n",
    "laptop\n",
    "mouse\n",
    "remote\n",
    "keyboard\n",
    "cell phone\n",
    "microwave\n",
    "oven\n",
    "toaster\n",
    "sink\n",
    "refrigerator\n",
    "book\n",
    "clock\n",
    "vase\n",
    "scissors\n",
    "teddy bear\n",
    "hair drier\n",
    "toothbrush'''.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is from yolo3.utils.letterbox_image\n",
    "def letterbox_image(image, size):\n",
    "    '''resize image with unchanged aspect ratio using padding'''\n",
    "    iw, ih = image.size\n",
    "    w, h = size\n",
    "    scale = min(w/iw, h/ih)\n",
    "    nw = int(iw*scale)\n",
    "    nh = int(ih*scale)\n",
    "\n",
    "    image = image.resize((nw,nh), Image.BICUBIC)\n",
    "    new_image = Image.new('RGB', size, (128,128,128))\n",
    "    new_image.paste(image, ((w-nw)//2, (h-nh)//2))\n",
    "    return new_image\n",
    "\n",
    "def preprocess(img):\n",
    "    model_image_size = (416, 416)\n",
    "    boxed_image = letterbox_image(img, tuple(reversed(model_image_size)))\n",
    "    image_data = np.array(boxed_image, dtype='float32')\n",
    "    image_data /= 255.\n",
    "    image_data = np.transpose(image_data, [2, 0, 1])\n",
    "    image_data = np.expand_dims(image_data, 0)\n",
    "    return image_data\n",
    "\n",
    "def bb_intersection_over_union(boxA, boxB):\n",
    "    \"\"\"\n",
    "    source\n",
    "    https://gist.github.com/meyerjo/dd3533edc97c81258898f60d8978eddc\n",
    "    \"\"\"\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = abs(max((xB - xA, 0)) * max((yB - yA), 0))\n",
    "    if interArea == 0:\n",
    "        return 0\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = abs((boxA[2] - boxA[0]) * (boxA[3] - boxA[1]))\n",
    "    boxBArea = abs((boxB[2] - boxB[0]) * (boxB[3] - boxB[1]))\n",
    "\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "\n",
    "    # return the intersection over union value\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(ses, img_path='pingguo.png', threshold=0.1, overlap_threhold=0.5):\n",
    "    image = Image.open(img_path)\n",
    "    image = image.resize((456, 456))\n",
    "    # input\n",
    "    image_data = preprocess(image)\n",
    "    image_size = np.array([image.size[1], image.size[0]], dtype=np.float32).reshape(1, 2)\n",
    "    outputs = ses.run(None, {'input_1': image_data, 'image_shape': image_size})\n",
    "    n_candidates = outputs[0].shape[1]\n",
    "    i_batch = 0\n",
    "    ret = []\n",
    "    for i in range(n_candidates):\n",
    "        scores = outputs[1][i_batch, :, i]\n",
    "        cls = np.argmax(scores)\n",
    "        score = np.max(scores)\n",
    "        box = outputs[0][i_batch, i]\n",
    "        ret.append({\n",
    "            'score': score,\n",
    "            'cls': class_names[cls],\n",
    "            'box': box,\n",
    "        })\n",
    "    ret = sorted(ret, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "    filtered_ret = []\n",
    "    for item in ret:\n",
    "        if item['score'] > threshold:\n",
    "            bad = False\n",
    "            for other in filtered_ret:\n",
    "                if bb_intersection_over_union(item['box'], other['box']) > overlap_threhold:\n",
    "                    bad = True\n",
    "                    break\n",
    "            if not bad:\n",
    "                filtered_ret.append(item)\n",
    "    return filtered_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses = onnxruntime.InferenceSession('tiny-yolov3-11.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.7782772,\n",
       "  'cls': 'apple',\n",
       "  'box': array([ 60.206234,  68.00511 , 231.40326 , 188.97191 ], dtype=float32)},\n",
       " {'score': 0.73667014,\n",
       "  'cls': 'apple',\n",
       "  'box': array([144.23593, 294.85623, 318.25494, 431.44476], dtype=float32)},\n",
       " {'score': 0.67745084,\n",
       "  'cls': 'apple',\n",
       "  'box': array([166.161  , 177.62476, 347.23557, 308.32822], dtype=float32)},\n",
       " {'score': 0.58755594,\n",
       "  'cls': 'apple',\n",
       "  'box': array([ 49.135155, 177.81197 , 209.82591 , 306.37067 ], dtype=float32)}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_image(ses, '../pingguo.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.8140421,\n",
       "  'cls': 'bowl',\n",
       "  'box': array([367.13654, 163.7141 , 427.2709 , 284.0218 ], dtype=float32)},\n",
       " {'score': 0.122924425,\n",
       "  'cls': 'person',\n",
       "  'box': array([ 88.40096,  85.63117, 441.62698, 360.64908], dtype=float32)}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_image(ses, '../meinv.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_image(ses, '../dahai2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
